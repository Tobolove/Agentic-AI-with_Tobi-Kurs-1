{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0dd2585",
   "metadata": {},
   "source": [
    "# CoT & ReACT Prompting Introcution\n",
    "React Prompting verbindet die Vorteile von LLMs \"Reasoning\" und erweitert sie mit weiteren Funktionalitäten, die normale LLMs nicht können. ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5335e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- 1. Konfiguration und Initialisierung ---\n",
    "\n",
    "# Lade alle Umgebungsvariablen aus der .env Datei\n",
    "load_dotenv()\n",
    "\n",
    "# Konfiguration für Azure OpenAI\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-01\")\n",
    "\n",
    "if not api_key or not azure_endpoint or not azure_deployment:\n",
    "    raise ValueError(\"Azure OpenAI Konfiguration fehlt. Bitte überprüfe deine .env Datei.\")\n",
    "\n",
    "# Initialisiere den Azure OpenAI Client\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=azure_endpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d404e",
   "metadata": {},
   "source": [
    "# Das Problem\n",
    "LLMs sind reine Sprachmodelle sind stateless und haben keine Zugang zu externen Tools. ChatGPT ist ein Finegetunetes LLM mit Tool Access und geht weit über ein herkömmliches LLM hinaus, viele sprechen bei ChatGPT bereits von einer Application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f50b554d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es tut mir leid, aber ich kann keine aktuellen Wetterdaten abrufen. Für die aktuelle Wetterlage in Dättwil empfehle ich, eine Wetter-Website oder eine Wetter-App zu nutzen, wie zum Beispiel Wetter.com, MeteoSchweiz oder eine ähnliche Plattform.\n"
     ]
    }
   ],
   "source": [
    "basic_user_prompt = \"Wie ist das Wetter gerade in Dättwil?\"\n",
    "basic_system_prompt = \"Du bist ein hilfreicher Assistent.\"\n",
    "\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": basic_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": basic_user_prompt}\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=azure_deployment,\n",
    "    messages=messages,\n",
    "    temperature=0\n",
    ")   \n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a8cbab",
   "metadata": {},
   "source": [
    "# Chain of Thought Prompting\n",
    "Die Idee hier ist super einfach, aber genial. Anstatt dem LLM nur zu sagen: 'Hier ist das Problem, gib mir die Antwort', zwingen wir es, seinen Denkprozess offenzulegen. Wir sagen quasi: 'Denk laut nach und zeig mir deine Arbeit, Schritt für Schritt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00929dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Um das aktuelle Wetter in Dättwil zu erfahren, kannst du folgende Schritte unternehmen:\n",
      "\n",
      "1. **Online-Wetterdienste nutzen**: \n",
      "   - Besuche Websites wie Wetter.com, MeteoSchweiz oder Weather.com.\n",
      "   - Gib „Dättwil“ in die Suchleiste ein, um die aktuellen Wetterdaten zu erhalten.\n",
      "\n",
      "2. **Wetter-Apps verwenden**:\n",
      "   - Öffne eine Wetter-App auf deinem Smartphone (z.B. Wetter.com, AccuWeather, MeteoSwiss).\n",
      "   - Suche nach „Dättwil“ und schaue dir die aktuellen Wetterbedingungen an.\n",
      "\n",
      "3. **Sprachassistenten fragen**:\n",
      "   - Nutze Sprachassistenten wie Siri, Google Assistant oder Alexa und frage: „Wie ist das Wetter gerade in Dättwil?“\n",
      "\n",
      "Da ich keine Echtzeitdaten abrufen kann, empfehle ich dir, eine der oben genannten Methoden zu verwenden, um die aktuellen Wetterinformationen zu erhalten. Wenn du möchtest, kann ich dir auch eine Anleitung geben, wie du eine Wetter-API nutzen kannst, um das Wetter programmatisch abzufragen.\n"
     ]
    }
   ],
   "source": [
    "basic_user_prompt = \"Wie ist das Wetter gerade in Dättwil?\"\n",
    "basic_system_prompt = \"\"\"Du bist ein hilfreicher Assistent, der Schritt für Schritt denkt, bevor er antwortet. \n",
    "Zerlege das Problem in kleinere Teile und gib Lösungsvorschläge für die einzelnen Schritte.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": basic_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": basic_user_prompt}\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=azure_deployment,\n",
    "    messages=messages,\n",
    "    temperature=0\n",
    ")   \n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2297efc3",
   "metadata": {},
   "source": [
    "# Lösung ReACT Prompting\n",
    "Um unserem LLM, die Fähigkeit zu geben auf Wetterdaten zuzugreifen brauchen wir ein ReACT Framework mit API Function Call zu einem Wetter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab6ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get_weather Funktion\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Ermittelt das Echtzeit-Wetter für eine Stadt.\"\"\"\n",
    "    print(f\"[Tool Called]: get_weather(city='{city}')\")\n",
    "    API_KEY = os.getenv('GOOGLE_MAPS_API_KEY')\n",
    "    if not API_KEY:\n",
    "        return json.dumps({\"error\": \"Google Maps API Key nicht gefunden.\"})\n",
    "    geo_url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={city}&key={API_KEY}\"\n",
    "    try:\n",
    "        geo_response = requests.get(geo_url)\n",
    "        geo_data = geo_response.json()\n",
    "        if geo_data['status'] == 'OK':\n",
    "            location = geo_data['results'][0]['geometry']['location']\n",
    "            lat, lon = location['lat'], location['lng']\n",
    "            weather_url = f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true\"\n",
    "            weather_response = requests.get(weather_url)\n",
    "            weather_data = weather_response.json()\n",
    "            return json.dumps(weather_data.get(\"current_weather\", {}))\n",
    "        else:\n",
    "            return json.dumps({\"error\": \"Stadt nicht gefunden.\"})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"API Fehler: {e}\"})\n",
    "\n",
    "# Final_answer Funktion\n",
    "def final_answer(summary: str) -> str:\n",
    "    \"\"\"Gibt die endgültige Antwort aus.\"\"\"\n",
    "    print(f\"\\n>>> Final Answer: {summary}\")\n",
    "    return \"Execution finished.\"\n",
    "\n",
    "available_tools = {\"get_weather\": get_weather, \"final_answer\": final_answer}\n",
    "\n",
    "\n",
    "# Hilfsfunktion zum Abrufen von LLM-Antworten\n",
    "def parse_action(ai_response: str):\n",
    "    \"\"\"Extrahiert den Werkzeugaufruf aus der LLM-Antwort.\"\"\"\n",
    "    try:\n",
    "        act_line = next(line for line in ai_response.splitlines() if line.startswith('ACT:'))\n",
    "        action_str = act_line[len('ACT: '):].strip()\n",
    "        tool_name = action_str[:action_str.find('(')]\n",
    "        args_str = action_str[action_str.find('(')+1:-1]\n",
    "        args = {}\n",
    "        if '=' in args_str:\n",
    "            key, value = args_str.split('=', 1)\n",
    "            args[key.strip()] = value.strip().strip('\\\"\\'')\n",
    "        return tool_name, args\n",
    "    except (StopIteration, ValueError):\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc439f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompt für ReAct\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that can access external tools.\n",
    "You must use a step-by-step reasoning process. For each step, respond with a single THINK/ACT block.\n",
    "\n",
    "THINK: Reason about the problem and decide the next logical action.\n",
    "ACT: Call ONE of the available tools. Use the format `tool_name(parameter=\"value\")`.\n",
    "\n",
    "# AVAILABLE TOOLS\n",
    "---\n",
    "## 1. get_weather(city: str)\n",
    "* Use this to get the weather for a specific city.\n",
    "* Example Input: `ACT: get_weather(city=\"Zurich\")`\n",
    "\n",
    "## 2. final_answer(summary: str)\n",
    "* Use this tool ONLY when you have all the information to answer the user's request.\n",
    "* Example Input: `ACT: final_answer(summary=\"The weather in Zurich is 15°C.\")`\n",
    "---\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4d98409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Wie ist das Wetter gerade in Dättwil?\n",
      "\n",
      "--- Turn 1 ---\n",
      "AI Assistant:\n",
      "ACT: get_weather(city=\"Dättwil\")\n",
      "\n",
      "[Tool Called]: get_weather(city='Dättwil')\n",
      "OBSERVE: {\"time\": \"2025-09-15T09:30\", \"interval\": 900, \"temperature\": 20.7, \"windspeed\": 14.7, \"winddirection\": 245, \"is_day\": 1, \"weathercode\": 3}\n",
      "\n",
      "--- Turn 2 ---\n",
      "AI Assistant:\n",
      "ACT: final_answer(summary=\"Das aktuelle Wetter in Dättwil ist bewölkt mit einer Temperatur von 20,7°C. Der Wind weht mit einer Geschwindigkeit von 14,7 km/h aus Richtung 245 Grad.\")\n",
      "\n",
      "\n",
      ">>> Final Answer: Das aktuelle Wetter in Dättwil ist bewölkt mit einer Temperatur von 20,7°C. Der Wind weht mit einer Geschwindigkeit von 14,7 km/h aus Richtung 245 Grad.\n",
      "OBSERVE: Execution finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Die Live ReAct-Schleife (Orchestrator) ---\n",
    "\n",
    "def main():\n",
    "    \"\"\"Führt die Live-Interaktion mit dem LLM aus.\"\"\"\n",
    "    user_prompt = \"Wie ist das Wetter gerade in Dättwil?\"\n",
    "    print(f\"User: {user_prompt}\\n\")\n",
    "\n",
    "    # Die Konversationshistorie, die wir an das LLM senden.\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    turn_count = 1\n",
    "    while turn_count <= 5: # Sicherheitslimit, um Endlosschleifen zu vermeiden\n",
    "        print(f\"--- Turn {turn_count} ---\")\n",
    "        \n",
    "        # 1. Das LLM \"denkt\" und generiert eine Antwort\n",
    "        response = client.chat.completions.create(\n",
    "            model=azure_deployment,\n",
    "            messages=messages,\n",
    "            temperature=0\n",
    "        )\n",
    "        ai_response_text = response.choices[0].message.content\n",
    "        print(f\"AI Assistant:\\n{ai_response_text}\\n\")\n",
    "        messages.append({\"role\": \"assistant\", \"content\": ai_response_text})\n",
    "\n",
    "        # 2. Wir parsen die Aktion aus der Antwort\n",
    "        tool_name, args = parse_action(ai_response_text)\n",
    "        if not tool_name or tool_name not in available_tools:\n",
    "            print(\"Could not parse a valid tool. Ending.\")\n",
    "            break\n",
    "\n",
    "        # 3. Wir führen das Werkzeug aus\n",
    "        tool_function = available_tools[tool_name]\n",
    "        observation = tool_function(**args)\n",
    "        observation_message = f\"OBSERVE: {observation}\"\n",
    "        print(f\"{observation_message}\\n\")\n",
    "        \n",
    "        # 4. Wir fügen das Ergebnis zur Historie hinzu, damit das LLM im nächsten Schritt darauf reagieren kann\n",
    "        messages.append({\"role\": \"user\", \"content\": observation_message})\n",
    "\n",
    "        # 5. Wenn die finale Antwort gegeben wurde, beenden wir die Schleife\n",
    "        if tool_name == \"final_answer\":\n",
    "            break\n",
    "            \n",
    "        turn_count += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
